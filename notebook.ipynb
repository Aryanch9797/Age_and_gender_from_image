{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":119874,"databundleVersionId":14372465,"sourceType":"competition"},{"sourceId":633949,"sourceType":"modelInstanceVersion","modelInstanceId":477966,"modelId":493889},{"sourceId":634909,"sourceType":"modelInstanceVersion","modelInstanceId":478694,"modelId":494535},{"sourceId":636897,"sourceType":"modelInstanceVersion","modelInstanceId":480205,"modelId":495897}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:10.279018Z","iopub.execute_input":"2025-11-10T08:03:10.279325Z","iopub.status.idle":"2025-11-10T08:03:10.283790Z","shell.execute_reply.started":"2025-11-10T08:03:10.279304Z","shell.execute_reply":"2025-11-10T08:03:10.282997Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Importing required Libraries","metadata":{}},{"cell_type":"code","source":"# importing pytorch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset, DataLoader\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Running on {device}\")\n\n# Sets the seed for random number generation on the CPU\ntorch.manual_seed(42)\n\n# Sets the seed for random number generation on all GPUs\ntorch.cuda.manual_seed_all(42)\n\n# torchvision to convert .jpg into tensor\nfrom torchvision import transforms\nimport torchvision.models as models\nimport torchvision\n\n# to visualize images\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport os\nimport kagglehub\nimport pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import train_test_split\n# import trackio\nfrom sklearn.metrics import f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:10.285248Z","iopub.execute_input":"2025-11-10T08:03:10.285864Z","iopub.status.idle":"2025-11-10T08:03:10.301776Z","shell.execute_reply.started":"2025-11-10T08:03:10.285844Z","shell.execute_reply":"2025-11-10T08:03:10.300963Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Huggingface Access Adding token to environment variable\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nimport os\nhf_token = user_secrets.get_secret(\"hf_token\")\nos.environ['HF_TOKEN'] = hf_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:10.302594Z","iopub.execute_input":"2025-11-10T08:03:10.302848Z","iopub.status.idle":"2025-11-10T08:03:10.451412Z","shell.execute_reply.started":"2025-11-10T08:03:10.302825Z","shell.execute_reply":"2025-11-10T08:03:10.450787Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Importing data","metadata":{}},{"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/sep-25-dl-gen-ai-nppe-1/face_dataset/sample_submission.csv\")\ntrain_df = pd.read_csv(\"/kaggle/input/sep-25-dl-gen-ai-nppe-1/face_dataset/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/sep-25-dl-gen-ai-nppe-1/face_dataset/test.csv\")\n\nprint(\"train_df: \\n\")\nprint(train_df.head())\n\nprint(\"test_df: \\n\")\nprint(test_df.head())\n\nprint(\"sample_submission: \\n\")\nprint(sample_submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:10.452134Z","iopub.execute_input":"2025-11-10T08:03:10.452376Z","iopub.status.idle":"2025-11-10T08:03:10.497434Z","shell.execute_reply.started":"2025-11-10T08:03:10.452358Z","shell.execute_reply":"2025-11-10T08:03:10.496693Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_path = \"/kaggle/input/sep-25-dl-gen-ai-nppe-1/face_dataset/\"\n# fig , axes = plt.subplots(2,3,figsize=(12, 8))\n# axes = axes.flatten()\n# for i,(index , path , gender , age) in enumerate(train_df.sample(6,random_state=42).values):\n#     img = Image.open(data_path+path)\n#     axes[i].imshow(img)\n#     axes[i].set_title(f\"Gender: {gender}, Age: {age}\", fontsize=14)\n#     axes[i].axis(\"off\")\n\n# plt.tight_layout()\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:10.499662Z","iopub.execute_input":"2025-11-10T08:03:10.500114Z","iopub.status.idle":"2025-11-10T08:03:10.503591Z","shell.execute_reply.started":"2025-11-10T08:03:10.500096Z","shell.execute_reply":"2025-11-10T08:03:10.502841Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Gender 1 correspond to Male \n\nGender 0 correspond to Female","metadata":{}},{"cell_type":"markdown","source":"# Creating Train and Validation split","metadata":{}},{"cell_type":"code","source":"train_df, val_df = train_test_split(train_df, test_size=0.05, random_state=42, stratify=train_df['gender'])\nprint(f\"train shape:{train_df.shape}\")\nprint(f\"validation shape:{val_df.shape}\")\nmin_age = train_df[\"age\"].min()\nmax_age = train_df[\"age\"].max()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:10.504254Z","iopub.execute_input":"2025-11-10T08:03:10.504458Z","iopub.status.idle":"2025-11-10T08:03:10.536968Z","shell.execute_reply.started":"2025-11-10T08:03:10.504443Z","shell.execute_reply":"2025-11-10T08:03:10.536118Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Converting image to tensor and creating DataLoaders.","metadata":{}},{"cell_type":"markdown","source":"## Creating custom class for Train and validation data.","metadata":{}},{"cell_type":"code","source":"class FaceData(Dataset):\n    \"\"\" Custom Dataset class so that we can use dataloader\"\"\"\n    \n    def __init__(self,df,data_path=\"/kaggle/input/sep-25-dl-gen-ai-nppe-1/face_dataset/\",transform=None):\n        \n        self.df = df\n        self.data_path = data_path\n        self.transform= transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        \n        row = self.df.iloc[idx]\n        \n        img_path = row[\"full_path\"]\n        gender = row[\"gender\"]\n        age = row[\"age\"]\n        \n        img = Image.open(self.data_path+img_path)\n\n        img_tensor = self.transform(img)\n\n\n        \n        return img_tensor , torch.tensor(gender, dtype=torch.float32) , torch.tensor(age, dtype=torch.float32)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:10.537815Z","iopub.execute_input":"2025-11-10T08:03:10.538085Z","iopub.status.idle":"2025-11-10T08:03:10.544023Z","shell.execute_reply.started":"2025-11-10T08:03:10.538062Z","shell.execute_reply":"2025-11-10T08:03:10.543217Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Creating custom class for Test data.","metadata":{}},{"cell_type":"code","source":"class facetest(Dataset):\n    \"\"\" Custom class for testdataset  \"\"\"\n    \n    def __init__(self,df,data_path=\"/kaggle/input/sep-25-dl-gen-ai-nppe-1/face_dataset/\",transform=None):\n        \n        self.df = df\n        self.data_path = data_path\n        self.transform= transform\n\n    def __len__(self):\n\n        return len(self.df)\n\n    def __getitem__(self,idx):\n        \n        row = self.df.iloc[idx]\n        path = row[\"full_path\"]\n        img = Image.open(self.data_path+path)\n\n        img_tensor = self.transform(img)\n\n        return img_tensor\n        \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:10.544793Z","iopub.execute_input":"2025-11-10T08:03:10.545087Z","iopub.status.idle":"2025-11-10T08:03:10.559241Z","shell.execute_reply.started":"2025-11-10T08:03:10.545061Z","shell.execute_reply":"2025-11-10T08:03:10.558633Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# transform will resize and then covert a image to tensor\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.Lambda(lambda im: im.convert('RGB')),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],    # standard image net parametrs for better results\n                         std=[0.229, 0.224, 0.225])\n])\n\n# transform with augmentation for training data\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.Lambda(lambda im: im.convert('RGB')),\n\n    transforms.RandomHorizontalFlip(p=0.5), # random flips\n    transforms.RandomRotation(15),          # random rotation\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), \n    \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:10.560125Z","iopub.execute_input":"2025-11-10T08:03:10.560508Z","iopub.status.idle":"2025-11-10T08:03:10.575083Z","shell.execute_reply.started":"2025-11-10T08:03:10.560487Z","shell.execute_reply":"2025-11-10T08:03:10.574230Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# creating FaceData object and then DataLoaders with batch size 32\ntrain_dataset = FaceData(train_df, data_path, transform=train_transform)\nval_dataset = FaceData(val_df, data_path, transform=val_transform)\ntest_dataset = facetest(test_df, data_path, transform=val_transform)\n\nprint(f\"Created {len(train_dataset)} training samples.\")\nprint(f\"Created {len(val_dataset)} validation samples.\")\nprint(f\"Created {len(test_dataset)} test samples.\")\n\nbatch_size = 32\n\ntrain_loader = DataLoader(\n    dataset=train_dataset,\n    batch_size = batch_size,\n    shuffle = True,\n    num_workers=4\n)\n\n\nval_loader = DataLoader(\n    dataset=val_dataset,\n    batch_size = batch_size,\n    shuffle = False\n)\n\ntest_loader = DataLoader(\n    dataset=test_dataset,\n    batch_size = batch_size,\n    shuffle = False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:10.576065Z","iopub.execute_input":"2025-11-10T08:03:10.576438Z","iopub.status.idle":"2025-11-10T08:03:10.599285Z","shell.execute_reply.started":"2025-11-10T08:03:10.576411Z","shell.execute_reply":"2025-11-10T08:03:10.598435Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# (Scratch CNN)","metadata":{}},{"cell_type":"code","source":"\n\n# class faceCnn2(nn.Module):\n#     def __init__(self , input_shape , hidden_shape ):\n#         super().__init__()\n\n#         self.conv_block_1 = nn.Sequential(\n#             nn.Conv2d(in_channels=input_shape , out_channels=hidden_shape , kernel_size=3 , stride=1 , padding=1),\n#             nn.ReLU(),\n#             nn.Conv2d(in_channels=hidden_shape , out_channels=hidden_shape*2 , kernel_size=3 , stride=1 , padding=1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2)\n#         )\n#         self.conv_block_2 = nn.Sequential(\n#             nn.Conv2d(in_channels=hidden_shape*2 , out_channels=hidden_shape*2 , kernel_size=3 , stride=1 , padding=1),\n#             nn.ReLU(),\n#             nn.Conv2d(in_channels=hidden_shape*2 , out_channels=hidden_shape*4 , kernel_size=3 , stride=1 , padding=1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2)\n#         )\n#         self.conv_block_3 = nn.Sequential(\n#             nn.Conv2d(in_channels=hidden_shape*4 , out_channels=hidden_shape*6 , kernel_size=3 , stride=1 , padding=1),\n#             nn.ReLU(),\n#             nn.Conv2d(in_channels=hidden_shape*6 , out_channels=hidden_shape*6 , kernel_size=3 , stride=1 , padding=1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2)\n#         )\n\n#         self.classifier = nn.Sequential(\n#             nn.Flatten(),\n#             nn.Linear(in_features=301056 , out_features=512),\n#             nn.ReLU(),\n#             nn.Dropout(p=0.3),\n#             )\n#         self.age_head = nn.Linear(in_features=512, out_features=1)\n#         self.gender_head = nn.Linear(in_features=512, out_features=1)\n        \n#     def forward(self , x):\n#         x = self.conv_block_1(x)\n#         x = self.conv_block_2(x)\n#         x = self.conv_block_3(x)\n#         x = self.classifier(x)\n#         gender = self.gender_head(x)\n#         age = self.age_head(x)\n#         return gender , age\n\n# model = faceCnn2(input_shape=3 , hidden_shape=64 ).to(device)\n# model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:10.600285Z","iopub.execute_input":"2025-11-10T08:03:10.600813Z","iopub.status.idle":"2025-11-10T08:03:12.085861Z","shell.execute_reply.started":"2025-11-10T08:03:10.600785Z","shell.execute_reply":"2025-11-10T08:03:12.085147Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Commom Training loop for Scratch CNN","metadata":{}},{"cell_type":"code","source":"# trackio.init(\n#     project=\"gen_ai_nppe\", \n#     space_id=\"Aryan9797/gen_ai\", \n#     name=\"scratch_cnn_final\", \n#     group=\"simple\"\n# )\n\n# optimizer = optim.Adam(model.parameters(),lr=0.01)\n# gender_loss_fn = nn.BCEWithLogitsLoss()\n# age_loss_fn = nn.MSELoss()\n\n# epochs = 10\n\n# for i in tqdm(range(epochs)):\n#     train_gender_loss = 0\n    # train_age_loss = 0\n    # train_total_loss = 0\n    # train_batch = 0\n    \n    # model.train()\n\n    # for batch ,(x,gender,age) in enumerate(train_loader):\n    #     x = x.to(device)\n    #     gender = gender.to(device)\n    #     age = age.to(device)\n        \n\n    #     optimizer.zero_grad()\n    #     pred_gender , pred_age = model(x)\n\n    #     gender_loss = gender_loss_fn(pred_gender,gender.unsqueeze(1))\n    #     age_loss = age_loss_fn(pred_age,age.unsqueeze(1))\n        \n    #     train_gender_loss+=gender_loss.item()\n    #     train_age_loss+= age_loss.item()\n        \n    #     total_loss = age_loss + gender_loss\n    #     train_total_loss+=total_loss.item()\n        \n    #     total_loss.backward()\n    #     optimizer.step()\n    #     train_batch+=1\n\n    \n    # val_gender_loss = 0\n    # val_age_loss = 0\n    # val_batch = 0\n    # val_total_loss = 0\n            \n    # model.eval()\n    # for batch ,(x,gender,age) in enumerate(val_loader):\n    #     x = x.to(device)\n    #     gender = gender.to(device)\n    #     age = age.to(device)\n\n    #     with torch.inference_mode():\n    #         pred_gender , pred_age = model(x)\n    #         gender_loss = gender_loss_fn(pred_gender,gender.unsqueeze(1))\n    #         age_loss = age_loss_fn(pred_age,age.unsqueeze(1))\n\n#             total_loss = gender_loss + age_loss\n#             val_total_loss += total_loss.item()\n#             val_gender_loss+=gender_loss.item()\n#             val_age_loss+= age_loss.item()\n#             val_batch+=1\n    \n#     trackio.log({\n#         \"train_gender_loss\" : train_gender_loss/train_batch,\n#         \"train_age_loss\" : train_age_loss/train_batch,\n#         \"train_total_loss\": train_total_loss/train_batch,\n#         \"validation_gender_loss\" : val_gender_loss/val_batch,\n#         \"validation_age_loss\" : val_age_loss/val_batch,\n#         \"validation_total_loss\":val_total_loss/val_batch\n#     })\n#     print(f\"Epoch {i+1}/{epochs} | Train Gender Loss: {train_gender_loss/train_batch} | Train Age Loss: {train_age_loss/train_batch} | Train_total_loss: {train_total_loss/train_batch} | Val Gender Loss: {val_gender_loss/val_batch} | Val Age Loss: {val_age_loss/val_batch} | Validation_total_loss: {val_total_loss/val_batch}\")\n\n# trackio.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:12.086612Z","iopub.execute_input":"2025-11-10T08:03:12.086864Z","iopub.status.idle":"2025-11-10T08:03:12.091099Z","shell.execute_reply.started":"2025-11-10T08:03:12.086835Z","shell.execute_reply":"2025-11-10T08:03:12.090563Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# model 3 (Finetuned CNN)","metadata":{}},{"cell_type":"code","source":"# model 3 with transfer learning \nimport torchvision.models as models\n\nclass EfficientNetFaceModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        # loading  pre-trained EfficientNet-B4\n        weights = models.EfficientNet_B4_Weights.IMAGENET1K_V1\n        self.backbone = models.efficientnet_b4(weights=weights)\n        in_features = self.backbone.classifier[1].in_features \n        \n        # freeze the backbone\n        for param in self.backbone.features.parameters():\n            param.requires_grad = False\n        self.backbone.classifier = nn.Identity()\n\n        \n        head_hidden_features = 512\n        \n        self.age_head = nn.Sequential(\n            nn.Dropout(p=0.5),\n            nn.Linear(in_features, head_hidden_features),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(head_hidden_features, 1), # output 1 value for age\n        )\n\n    #     # Do the same for self.gender_head\n        self.gender_head = nn.Sequential(\n            nn.Dropout(p=0.5),\n            nn.Linear(in_features, head_hidden_features),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(head_hidden_features, 1) # output 1 logit for gender\n        )\n\n    def forward(self, x):\n        x = self.backbone.features(x)\n        x = self.backbone.avgpool(x)\n        x = torch.flatten(x, 1)\n        \n        gender = self.gender_head(x)\n        age = self.age_head(x)\n        \n        return gender, age\n\n\nmodel2 = EfficientNetFaceModel().to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:12.091863Z","iopub.execute_input":"2025-11-10T08:03:12.092110Z","iopub.status.idle":"2025-11-10T08:03:12.109445Z","shell.execute_reply.started":"2025-11-10T08:03:12.092093Z","shell.execute_reply":"2025-11-10T08:03:12.108565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom torchvision.models import ConvNeXt_Base_Weights, convnext_base\n\nclass ConvNeXtFaceModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        weights = ConvNeXt_Base_Weights.IMAGENET1K_V1\n        self.backbone = convnext_base(weights=weights)\n        \n\n        in_features = self.backbone.classifier[2].in_features\n        \n\n        for param in self.backbone.features.parameters():\n            param.requires_grad = False\n            \n\n        self.backbone.classifier = nn.Identity()\n\n        head_hidden_features = 512\n        \n\n        self.age_head = nn.Sequential(\n            nn.Dropout(p=0.5),\n            nn.Linear(in_features, head_hidden_features),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(head_hidden_features, 1),\n        )\n\n        self.gender_head = nn.Sequential(\n            nn.Dropout(p=0.5),\n            nn.Linear(in_features, head_hidden_features),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(head_hidden_features, 1)\n        )\n        \n\n    def forward(self, x):\n        x = self.backbone.features(x)\n        x = self.backbone.avgpool(x)\n        \n        x = torch.flatten(x, 1)\n        \n        gender = self.gender_head(x)\n        age = self.age_head(x)\n        \n        return gender, age\n\nmodel = ConvNeXtFaceModel().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:12.111812Z","iopub.execute_input":"2025-11-10T08:03:12.112236Z","iopub.status.idle":"2025-11-10T08:03:12.127551Z","shell.execute_reply.started":"2025-11-10T08:03:12.112213Z","shell.execute_reply":"2025-11-10T08:03:12.126767Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training for Finetuned CNN","metadata":{}},{"cell_type":"code","source":"# trackio.init(\n#     project=\"gen_ai_nppe\", \n#     space_id=\"Aryan9797/gen_ai\", \n#     name=\"transfer_with_0.5drop\", \n#     group=\"simple\"\n# )\n\n# male_count = (train_df['gender'] == 1).sum()\n# female_count = (train_df['gender'] == 0).sum()\n# total = len(train_df)\n\n# pos_weight = torch.tensor([female_count / male_count]).to(device)\n\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n# scheduler = optim.lr_scheduler.ReduceLROnPlateau(       # lr_scheduler to reduce learning_rate when close to convergence\n#     optimizer, \n#     mode='min',   \n#     factor=0.1,    \n#     patience=2,     \n#     verbose=True\n# )\n\n# gender_loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n# age_loss_fn = nn.HuberLoss(delta=1.0)\n\n# # Training only added layers with frozen model\n\n# epochs = 20\n# for i in tqdm(range(epochs), desc=\"Stage 1 (Head)\"):\n#     train_gender_loss = 0\n#     train_age_loss = 0\n#     train_total_loss = 0\n#     train_batch = 0\n    \n#     model.train()\n#     for batch ,(x,gender,age) in enumerate(train_loader):\n#         x = x.to(device)\n#         gender = gender.to(device)\n#         age = age.to(device)\n        \n#         optimizer.zero_grad()\n#         pred_gender , pred_age = model(x)\n        \n#         g_loss = gender_loss_fn(pred_gender,gender.unsqueeze(1))\n#         a_loss_mse = age_loss_fn(pred_age,age.unsqueeze(1)) \n        \n#         train_gender_loss+=g_loss.item()\n#         train_age_loss+= a_loss_mse.item() \n        \n#         age_weight = 0.3            # weighted loss as unit for age is larger then the unit for gender\n#         gender_weight = 1.0\n#         total_loss = (age_weight * a_loss_mse) + (gender_weight * g_loss)\n        \n    #     train_total_loss+=total_loss.item()\n        \n    #     total_loss.backward()\n    #     optimizer.step()\n    #     train_batch+=1\n    \n    # val_gender_loss = 0\n    # val_age_loss = 0\n    # val_batch = 0\n    # val_total_loss = 0\n            \n    # model.eval()\n    # for batch ,(x,gender,age) in enumerate(val_loader):\n    #     x = x.to(device)\n    #     gender = gender.to(device)\n    #     age = age.to(device)\n\n    #     with torch.inference_mode():\n    #         pred_gender , pred_age = model(x)\n            \n    #         g_loss = gender_loss_fn(pred_gender,gender.unsqueeze(1))\n    #         a_loss_mse = age_loss_fn(pred_age,age.unsqueeze(1)) \n            \n    #         age_weight = 0.3\n    #         gender_weight = 1.0\n    #         total_loss = (age_weight * a_loss_mse) + (gender_weight * g_loss)\n            \n    #         val_total_loss += total_loss.item()\n            \n#             val_gender_loss+=g_loss.item()\n#             val_age_loss+= a_loss_mse.item() \n#             val_batch+=1\n            \n#     val_loss_for_scheduler = val_total_loss / val_batch\n#     scheduler.step(val_loss_for_scheduler)\n    \n#     trackio.log({\n#         \"epoch\": i,\n#         \"train_gender_loss\" : train_gender_loss/train_batch,\n#         \"train_age_loss\" : train_age_loss/train_batch,\n#         \"train_total_loss\": train_total_loss/train_batch,\n#         \"validation_gender_loss\" : val_gender_loss/val_batch,\n#         \"validation_age_loss\" : val_age_loss/val_batch,\n#         \"validation_total_loss\":val_total_loss/val_batch,\n#     })\n#     print(f\"Epoch {i+1}/{epochs} | Train Gender Loss: {train_gender_loss/train_batch} | Train Age (RMSE) Loss: {train_age_loss/train_batch} | Train_total_loss: {train_total_loss/train_batch} | Val Gender Loss: {val_gender_loss/val_batch} | Val Age (RMSE) Loss: {val_age_loss/val_batch} | Validation_total_loss: {val_total_loss/val_batch}\")\n\n# # training whole model with low learning rate for fine-tuning\n\n# for param in model.backbone.features.parameters():\n#     param.requires_grad = True\n\n# optimizer = optim.Adam(model.parameters(), lr=0.00005) \n# scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n#     optimizer, \n#     mode='min',     \n#     factor=0.1,    \n#     patience=2,    \n#     verbose=True\n# )\n\n# epochs = 10\n# for i in tqdm(range(epochs), desc=\"Stage 2 (Fine-Tune)\"):\n#     train_gender_loss = 0\n#     train_age_loss = 0\n#     train_total_loss = 0\n#     train_batch = 0\n    \n#     model.train()\n#     for batch ,(x,gender,age) in enumerate(train_loader):\n#         x = x.to(device)\n#         gender = gender.to(device)\n#         age = age.to(device)\n        \n#         optimizer.zero_grad()\n#         pred_gender , pred_age = model(x)\n        \n#         g_loss = gender_loss_fn(pred_gender,gender.unsqueeze(1))\n#         a_loss_mse = age_loss_fn(pred_age,age.unsqueeze(1))\n        \n    #     train_gender_loss+=g_loss.item()\n    #     train_age_loss+= a_loss_mse.item()\n        \n    #     age_weight = 0.3\n    #     gender_weight = 1.0\n    #     total_loss = (age_weight * a_loss_mse) + (gender_weight * g_loss)\n        \n    #     train_total_loss+=total_loss.item()\n        \n    #     total_loss.backward()\n    #     optimizer.step()\n    #     train_batch+=1\n    \n    # val_gender_loss = 0\n    # val_age_loss = 0\n    # val_batch = 0\n    # val_total_loss = 0\n            \n    # model.eval()\n    # for batch ,(x,gender,age) in enumerate(val_loader):\n    #     x = x.to(device)\n    #     gender = gender.to(device)\n    #     age = age.to(device)\n\n    #     with torch.inference_mode():\n    #         pred_gender , pred_age = model(x)\n            \n    #         g_loss = gender_loss_fn(pred_gender,gender.unsqueeze(1))\n#             a_loss_mse = age_loss_fn(pred_age,age.unsqueeze(1))\n            \n#             age_weight = 0.3\n#             gender_weight = 1.0\n#             total_loss = (age_weight * a_loss_mse) + (gender_weight * g_loss)\n#             val_total_loss += total_loss.item()\n            \n#             val_gender_loss+=g_loss.item()\n#             val_age_loss+= a_loss_mse.item()\n#             val_batch+=1\n            \n#     val_loss_for_scheduler = val_total_loss / val_batch\n#     scheduler.step(val_loss_for_scheduler)\n    \n#     trackio.log({\n#         \"epoch\": i + 10, \n#         \"train_gender_loss\" : train_gender_loss/train_batch,\n#         \"train_age_loss\" : train_age_loss/train_batch,\n#         \"train_total_loss\": train_total_loss/train_batch,\n#         \"validation_gender_loss\" : val_gender_loss/val_batch,\n#         \"validation_age_loss\" : val_age_loss/val_batch,\n#         \"validation_total_loss\":val_total_loss/val_batch,\n#     })\n#     print(f\"Epoch {i+11}/{epochs+10} | Train Gender Loss: {train_gender_loss/train_batch} | Train Age (RMSE) Loss: {train_age_loss/train_batch} | Train_total_loss: {train_total_loss/train_batch} | Val Gender Loss: {val_gender_loss/val_batch} | Val Age (RMSE) Loss: {val_age_loss/val_batch} | Validation_total_loss: {val_total_loss/val_batch}\")\n\n# trackio.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:12.128571Z","iopub.execute_input":"2025-11-10T08:03:12.128798Z","iopub.status.idle":"2025-11-10T08:03:12.148558Z","shell.execute_reply.started":"2025-11-10T08:03:12.128768Z","shell.execute_reply":"2025-11-10T08:03:12.147851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# trackio.init(\n#     project=\"gen_ai_nppe\", \n#     space_id=\"Aryan9797/gen_ai\", \n#     name=\"ConvNeXt\", \n#     group=\"simple\"\n# )\n\n# male_count = (train_df['gender'] == 1).sum()\n# female_count = (train_df['gender'] == 0).sum()\n# total = len(train_df)\n\n# pos_weight = torch.tensor([female_count / male_count]).to(device)\n\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n# scheduler = optim.lr_scheduler.ReduceLROnPlateau(       # lr_scheduler to reduce learning_rate when close to convergence\n#     optimizer, \n#     mode='min',   \n#     factor=0.1,    \n#     patience=2,     \n#     verbose=True\n# )\n\n# gender_loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n# age_loss_fn = nn.HuberLoss(delta=1.0)\n\n## for early stoping\n# best_val_loss = float('inf')\n# patience_epochs = 5  # How many epochs to wait after last improvement\n# patience_counter = 0\n# BEST_MODEL_PATH = \"best_model.pth\"\n\n\n# # Training only added layers with frozen model\n\n# epochs = 40\n# for i in tqdm(range(epochs), desc=\"Stage 1 (Head)\"):\n    # train_gender_loss = 0\n    # train_age_loss = 0\n    # train_total_loss = 0\n    # train_batch = 0\n    \n    # model.train()\n    # for batch ,(x,gender,age) in enumerate(train_loader):\n    #     x = x.to(device)\n    #     gender = gender.to(device)\n    #     age = age.to(device)\n        \n    #     optimizer.zero_grad()\n    #     pred_gender , pred_age = model(x)\n        \n    #     g_loss = gender_loss_fn(pred_gender,gender.unsqueeze(1))\n    #     a_loss_mse = age_loss_fn(pred_age,age.unsqueeze(1)) \n        \n    #     train_gender_loss+=g_loss.item()\n    #     train_age_loss+= a_loss_mse.item() \n        \n    #     age_weight = 0.3        # weighted loss as unit for age is larger then the unit for gender\n    #     gender_weight = 1.0\n    #     total_loss = (age_weight * a_loss_mse) + (gender_weight * g_loss)\n        \n    #     train_total_loss+=total_loss.item()\n        \n    #     total_loss.backward()\n    #     optimizer.step()\n    #     train_batch+=1\n    \n    # val_gender_loss = 0\n    # val_age_loss = 0\n    # val_batch = 0\n    # val_total_loss = 0\n            \n    # model.eval()\n    # for batch ,(x,gender,age) in enumerate(val_loader):\n    #     x = x.to(device)\n    #     gender = gender.to(device)\n    #     age = age.to(device)\n\n    #     with torch.inference_mode():\n    #         pred_gender , pred_age = model(x)\n            \n    #         g_loss = gender_loss_fn(pred_gender,gender.unsqueeze(1))\n    #         a_loss_mse = age_loss_fn(pred_age,age.unsqueeze(1)) \n            \n    #         age_weight = 0.3\n    #         gender_weight = 1.0\n    #         total_loss = (age_weight * a_loss_mse) + (gender_weight * g_loss)\n            \n    #         val_total_loss += total_loss.item()\n            \n    #         val_gender_loss+=g_loss.item()\n    #         val_age_loss+= a_loss_mse.item() \n    #         val_batch+=1\n            \n    # val_loss_for_scheduler = val_total_loss / val_batch\n    # scheduler.step(val_loss_for_scheduler)\n    \n    # # EARLY STOPPING CHECK\n\n    # if val_loss_for_scheduler < best_val_loss:\n    #     print(f\"✅ Validation loss improved ({best_val_loss:.5f} -> {val_loss_for_scheduler:.5f}). Saving model...\")\n    #     best_val_loss = val_loss_for_scheduler\n    #     torch.save(model.state_dict(), BEST_MODEL_PATH)\n    #     patience_counter = 0  # Reset patience\n    # else:\n    #     patience_counter += 1\n    #     print(f\"Validation loss did not improve. Patience {patience_counter}/{patience_epochs}\")\n\n    # if patience_counter >= patience_epochs:\n    #     print(\"Stopping early due to lack of improvement.\")\n    #     break  # Exit the loop\n    # ============================================\n\n#     trackio.log({\n#         \"epoch\": i,\n#         \"train_gender_loss\" : train_gender_loss/train_batch,\n#         \"train_age_loss\" : train_age_loss/train_batch,\n#         \"train_total_loss\": train_total_loss/train_batch,\n#         \"validation_gender_loss\" : val_gender_loss/val_batch,\n#         \"validation_age_loss\" : val_age_loss/val_batch,\n#         \"validation_total_loss\":val_total_loss/val_batch,\n#     })\n#     print(f\"Epoch {i+1}/{epochs} | Train Gender Loss: {train_gender_loss/train_batch} | Train Age (RMSE) Loss: {train_age_loss/train_batch} | Train_total_loss: {train_total_loss/train_batch} | Val Gender Loss: {val_gender_loss/val_batch} | Val Age (RMSE) Loss: {val_age_loss/val_batch} | Validation_total_loss: {val_total_loss/val_batch}\")\n\n# # training whole model with low learning rate for fine-tuning\n\n# for param in model.backbone.features.parameters():\n#     param.requires_grad = True\n\n# optimizer = optim.Adam(model.parameters(), lr=0.00005) \n# scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n#     optimizer, \n#     mode='min',     \n#     factor=0.1,    \n#     patience=2,    \n#     verbose=True\n# )\n\n\n# patience_counter = 0\n# print(\"\\n--- Starting Stage 2 (Fine-Tune) ---\")\n# # =============================================\n\n# epochs = 40\n# for i in tqdm(range(epochs), desc=\"Stage 2 (Fine-Tune)\"):\n#     train_gender_loss = 0\n#     train_age_loss = 0\n#     train_total_loss = 0\n#     train_batch = 0\n    \n#     model.train()\n#     for batch ,(x,gender,age) in enumerate(train_loader):\n#         x = x.to(device)\n#         gender = gender.to(device)\n#         age = age.to(device)\n        \n#         optimizer.zero_grad()\n#         pred_gender , pred_age = model(x)\n        \n#         g_loss = gender_loss_fn(pred_gender,gender.unsqueeze(1))\n#         a_loss_mse = age_loss_fn(pred_age,age.unsqueeze(1))\n        \n    #     train_gender_loss+=g_loss.item()\n    #     train_age_loss+= a_loss_mse.item()\n        \n    #     age_weight = 0.3\n    #     gender_weight = 1.0\n    #     total_loss = (age_weight * a_loss_mse) + (gender_weight * g_loss)\n        \n    #     train_total_loss+=total_loss.item()\n        \n    #     total_loss.backward()\n    #     optimizer.step()\n    #     train_batch+=1\n    \n    # val_gender_loss = 0\n    # val_age_loss = 0\n    # val_batch = 0\n    # val_total_loss = 0\n            \n    # model.eval()\n    # for batch ,(x,gender,age) in enumerate(val_loader):\n    #     x = x.to(device)\n    #     gender = gender.to(device)\n    #     age = age.to(device)\n\n    #     with torch.inference_mode():\n    #         pred_gender , pred_age = model(x)\n            \n    #         g_loss = gender_loss_fn(pred_gender,gender.unsqueeze(1))\n    #         a_loss_mse = age_loss_fn(pred_age,age.unsqueeze(1))\n            \n    #         age_weight = 0.3\n    #         gender_weight = 1.0\n    #         total_loss = (age_weight * a_loss_mse) + (gender_weight * g_loss)\n    #         val_total_loss += total_loss.item()\n            \n    #         val_gender_loss+=g_loss.item()\n    #         val_age_loss+= a_loss_mse.item()\n    #         val_batch+=1\n            \n    # val_loss_for_scheduler = val_total_loss / val_batch\n    # scheduler.step(val_loss_for_scheduler)\n    \n    # # EARLY STOPPING CHECK ===\n    # if val_loss_for_scheduler < best_val_loss:\n    #     print(f\"✅ Validation loss improved ({best_val_loss:.5f} -> {val_loss_for_scheduler:.5f}). Saving model...\")\n    #     best_val_loss = val_loss_for_scheduler\n    #     torch.save(model.state_dict(), BEST_MODEL_PATH)\n    #     patience_counter = 0  # Reset patience\n    # else:\n    #     patience_counter += 1\n#         print(f\"Validation loss did not improve. Patience {patience_counter}/{patience_epochs}\")\n\n#     if patience_counter >= patience_epochs:\n#         print(\"Stopping early due to lack of improvement.\")\n#         break  # Exit the loop\n\n    \n#     trackio.log({\n#         \"epoch\": i + 10, \n#         \"train_gender_loss\" : train_gender_loss/train_batch,\n#         \"train_age_loss\" : train_age_loss/train_batch,\n#         \"train_total_loss\": train_total_loss/train_batch,\n#         \"validation_gender_loss\" : val_gender_loss/val_batch,\n#         \"validation_age_loss\" : val_age_loss/val_batch,\n#         \"validation_total_loss\":val_total_loss/val_batch,\n#     })\n#     print(f\"Epoch {i+11}/{epochs+10} | Train Gender Loss: {train_gender_loss/train_batch} | Train Age (RMSE) Loss: {train_age_loss/train_batch} | Train_total_loss: {train_total_loss/train_batch} | Val Gender Loss: {val_gender_loss/val_batch} | Val Age (RMSE) Loss: {val_age_loss/val_batch} | Validation_total_loss: {val_total_loss/val_batch}\")\n\n# trackio.finish()\n\n# # LOAD THE BEST MODEL BEFORE PREDICTION \n# print(f\"\\nTraining complete. Loading best model from {BEST_MODEL_PATH} with loss {best_val_loss:.5f}\")\n# model.load_state_dict(torch.load(BEST_MODEL_PATH))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:12.149430Z","iopub.execute_input":"2025-11-10T08:03:12.149642Z","iopub.status.idle":"2025-11-10T08:03:12.170225Z","shell.execute_reply.started":"2025-11-10T08:03:12.149619Z","shell.execute_reply":"2025-11-10T08:03:12.169594Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Saving model in kaggle hub","metadata":{}},{"cell_type":"code","source":"\n# MODEL_UPLOAD_DIR = \"/kaggle/working/my_face_model_v1\" \n# os.makedirs(MODEL_UPLOAD_DIR, exist_ok=True)\n\n# MODEL_SAVE_PATH = os.path.join(MODEL_UPLOAD_DIR, \"face_cnn_model.pth\")\n# torch.save(model.state_dict(), MODEL_SAVE_PATH)\n# print(f\"Model saved to {MODEL_SAVE_PATH}\")\n\n# KAGGLE_USERNAME = 'aryanchauhan97971234' \n# MODEL = 'sctrach_cnn_final'\n# FRAMEWORK = 'pytorch'\n# VARIATION = 'transfer_with_0.0001and0.01with_loss_weights'\n\n# handle = f'{KAGGLE_USERNAME}/{MODEL}/{FRAMEWORK}/{VARIATION}'\n\n# print(f\"Uploading model from {MODEL_UPLOAD_DIR} to {handle}...\")\n\n# kagglehub.model_upload(\n#     handle,                     \n#     MODEL_UPLOAD_DIR,           \n#     license_name=\"Apache 2.0\", \n#     version_notes=\"4th run with transfer, lr scheduler\"\n# )\n# print(\"Upload complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:12.171102Z","iopub.execute_input":"2025-11-10T08:03:12.171351Z","iopub.status.idle":"2025-11-10T08:03:12.189325Z","shell.execute_reply.started":"2025-11-10T08:03:12.171328Z","shell.execute_reply":"2025-11-10T08:03:12.188506Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Importing final model ","metadata":{}},{"cell_type":"code","source":"# handle = 'aryanchauhan97971234/sctrach_cnn_final/pytorch/transfer_with_0.0001and0.01with_loss_weights'\n# print(f\"Downloading model from {handle}...\")\n# model_dir = kagglehub.model_download(handle)\n# print(f\"Model downloaded to: {model_dir}\")\n# model_file_path = os.path.join(model_dir, \"face_cnn_model.pth\")\n# state_dict = torch.load(model_file_path, map_location=torch.device('cpu'))\n# model.load_state_dict(state_dict)\n# model.to(device)\n# print(\"Model weights loaded successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:12.190154Z","iopub.execute_input":"2025-11-10T08:03:12.190754Z","iopub.status.idle":"2025-11-10T08:03:45.318305Z","shell.execute_reply.started":"2025-11-10T08:03:12.190716Z","shell.execute_reply":"2025-11-10T08:03:45.317494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"handle = 'aryanchauhan97971234/face-age-transfer2-loss-weights/pytorch/transfer_with_0.0001and0.01with_loss_weights'\nprint(f\"Downloading model from {handle}...\")\nmodel_dir = kagglehub.model_download(handle)\nprint(f\"Model downloaded to: {model_dir}\")\nmodel_file_path = os.path.join(model_dir, \"face_cnn_model.pth\")\nstate_dict = torch.load(model_file_path, map_location=torch.device('cpu'))\nmodel2.load_state_dict(state_dict)\nmodel2.to(device)\nprint(\"Model weights loaded successfully!\")\n\nhandle = 'aryanchauhan97971234/ConvNeXt/pytorch/transfer_with_0.0001and0.01with_loss_weights'\nprint(f\"Downloading model from {handle}...\")\nmodel_dir = kagglehub.model_download(handle)\nprint(f\"Model downloaded to: {model_dir}\")\nmodel_file_path = os.path.join(model_dir, \"face_cnn_model.pth\")\nstate_dict = torch.load(model_file_path, map_location=torch.device('cpu'))\nmodel.load_state_dict(state_dict)\nmodel.to(device)\nprint(\"Model weights loaded successfully!\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:45.319047Z","iopub.execute_input":"2025-11-10T08:03:45.319366Z","iopub.status.idle":"2025-11-10T08:03:45.323059Z","shell.execute_reply.started":"2025-11-10T08:03:45.319347Z","shell.execute_reply":"2025-11-10T08:03:45.322469Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Creating final submission.csv","metadata":{}},{"cell_type":"code","source":"\nweight_model1 = 0.8  # 85% weight for the main model\nweight_model2 = 0.2  # 15% weight for the second model\n\n\ngender, age = [], []\nmodel.eval()\nmodel2.eval() \n\nwith torch.inference_mode():\n    for x in tqdm(test_loader):\n        x = x.to(device)\n        \n        # predictions for model 1 \n        pred_gender_orig, pred_age_orig = model(x)\n        x_flipped = torch.flip(x, [3]) \n        pred_gender_flip, pred_age_flip = model(x_flipped)\n        # Average for model 1\n        pred_gender_model1 = (pred_gender_orig + pred_gender_flip) / 2\n        pred_age_model1 = (pred_age_orig + pred_age_flip) / 2\n        \n        # predictions for model 2\n        pred_gender_orig2, pred_age_orig2 = model2(x)\n        pred_gender_flip2, pred_age_flip2 = model2(x_flipped)\n        # Average TTA for model 2\n        pred_gender_model2 = (pred_gender_orig2 + pred_gender_flip2) / 2\n        pred_age_model2 = (pred_age_orig2 + pred_age_flip2) / 2\n\n        # weighted average\n        pred_gender = (weight_model1 * pred_gender_model1) + (weight_model2 * pred_gender_model2)\n        pred_age = (weight_model1 * pred_age_model1) + (weight_model2 * pred_age_model2)\n        \n        # Convert to final predictions\n        pred_gender = (pred_gender.squeeze(1) > 0).int()  # Using 0 as threshold\n        gender.extend(pred_gender.detach().cpu().numpy().astype(int).tolist())\n        \n        pred_age = pred_age.squeeze(1).detach().cpu().numpy()\n        rounded_ages = np.round(pred_age).astype(int)\n        rounded_ages[rounded_ages < 0] = 0\n        age.extend(rounded_ages.tolist())\n\nprint(\"Gender samples:\", gender[:10])\nprint(\"Age samples:\", age[:10])\nsample_submission[\"gender\"] = gender\nsample_submission[\"age\"] = age\nsample_submission.to_csv(\"submission.csv\", index=False)\nprint(\"✅ CSV written.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:45.323872Z","iopub.execute_input":"2025-11-10T08:03:45.324113Z","iopub.status.idle":"2025-11-10T08:03:45.343048Z","shell.execute_reply.started":"2025-11-10T08:03:45.324087Z","shell.execute_reply":"2025-11-10T08:03:45.342409Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# gender, age = [], []\n# model.eval()\n\n# with torch.inference_mode():\n#     for x in tqdm(test_loader):\n#         x = x.to(device)\n        \n#         # predictions for model 1 \n#         pred_gender_orig, pred_age_orig = model(x)\n#         x_flipped = torch.flip(x, [3]) \n#         pred_gender_flip, pred_age_flip = model(x_flipped)\n#         # Average for model 1\n#         pred_gender_model1 = (pred_gender_orig + pred_gender_flip) / 2\n#         pred_age_model1 = (pred_age_orig + pred_age_flip) / 2\n\n#         # Convert to final predictions\n#         pred_gender = (pred_gender_model1.squeeze(1) > 0).int()  # Using 0 as threshold\n#         gender.extend(pred_gender.detach().cpu().numpy().astype(int).tolist())\n        \n#         pred_age = pred_age_model1.squeeze(1).detach().cpu().numpy()\n#         rounded_ages = np.round(pred_age).astype(int)\n#         rounded_ages[rounded_ages < 0] = 0\n#         age.extend(rounded_ages.tolist())\n\n# print(\"Gender samples:\", gender[:10])\n# print(\"Age samples:\", age[:10])\n# sample_submission[\"gender\"] = gender\n# sample_submission[\"age\"] = age\n# sample_submission.to_csv(\"submission.csv\", index=False)\n# print(\"✅ CSV written.\")\n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:03:45.343778Z","iopub.execute_input":"2025-11-10T08:03:45.344021Z","iopub.status.idle":"2025-11-10T08:05:30.281099Z","shell.execute_reply.started":"2025-11-10T08:03:45.344003Z","shell.execute_reply":"2025-11-10T08:05:30.280386Z"}},"outputs":[],"execution_count":null}]}